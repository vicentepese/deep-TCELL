{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import torch \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "import tokenizers\n",
    "\n",
    "from torch import tensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import  RobertaConfig\n",
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.models import WordLevel, BPE\n",
    "from tokenizers import pre_tokenizers, normalizers, Tokenizer\n",
    "from tokenizers.normalizers import Lowercase, NFD\n",
    "from tokenizers.pre_tokenizers import ByteLevel, Whitespace\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (l1): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(26, 1032, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 1032, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(2, 1032)\n",
       "      (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (classifier): Linear(in_features=1032, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load settings\n",
    "with open('settings.json', 'r') as inFile:\n",
    "    settings = json.load(inFile)\n",
    "    \n",
    "# Set device \n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load model\n",
    "model = torch.load('best_model')\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDR3Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, settings:dict, train:bool = True, label:str = None, tokenizer:tokenizers.Tokenizer=None, equal:bool=False) -> None:\n",
    "        cols = [\"activatedby_HA\", \"activatedby_NP\", \"activatedby_HCRT\", \"activated_any\", \"multilabel\", \"negative\"]\n",
    "        if label not in cols:\n",
    "            raise ValueError(\"Invalid label type. Expected one of %s\" % cols)\n",
    "        else: \n",
    "            self.label = label\n",
    "        if equal and label == \"num_label\":\n",
    "            raise ValueError(\"Equal size sets only allowed for binary classifications. num_label is multiclass.\")\n",
    "        \n",
    "        if train == True:\n",
    "            path_to_data = settings[\"file\"][\"train_data\"] \n",
    "        else:\n",
    "            path_to_data = settings[\"file\"][\"test_data\"]   \n",
    "              \n",
    "        self.path_to_data = path_to_data\n",
    "        self.data = pd.read_csv(self.path_to_data)\n",
    "        if equal == True:\n",
    "            min_sample=np.min(self.data[self.label].value_counts()) \n",
    "            data_pos = self.data[self.data[self.label]==1].sample(min_sample)\n",
    "            data_neg = self.data[self.data[self.label]==0].sample(min_sample)\n",
    "            self.data = pd.concat([data_pos, data_neg], ignore_index=True)\n",
    "        \n",
    "        if label == \"multilabel\":\n",
    "            self.labels = [0,1]\n",
    "            self.n_labels = 3\n",
    "        else:\n",
    "            self.labels = np.unique(self.data[[self.label]])\n",
    "            self.n_labels = len(self.labels)\n",
    "            \n",
    "        self.max_len = self.data.CDR3ab.str.len().max()\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __getitem__(self, index:int):\n",
    "        if isinstance(self.tokenizer.model, tokenizers.models.WordLevel):\n",
    "            self.tokenizer.enable_padding(length=self.max_len)\n",
    "            CDR3ab = \" \".join(list(self.data.CDR3ab[index]))\n",
    "            encodings = self.tokenizer.encode(CDR3ab)\n",
    "            item = {\n",
    "                \"ids\":tensor(encodings.ids, dtype=torch.long),\n",
    "                \"attention_mask\": tensor(encodings.attention_mask, dtype=torch.long),\n",
    "                \"CDR3ab\": self.data.CDR3ab[index]\n",
    "                }\n",
    "        elif isinstance(self.tokenizer.model, tokenizers.models.BPE):\n",
    "            self.tokenizer.enable_padding(length=self.max_len)\n",
    "            encodings = self.tokenizer.encode(self.data.CDR3ab[index]) \n",
    "            item = {\n",
    "                \"ids\":tensor(encodings.ids, dtype=torch.long),\n",
    "                \"attention_mask\": tensor(encodings.attention_mask, dtype=torch.long),\n",
    "                \"CDR3ab\": self.data.CDR3ab[index]\n",
    "                }\n",
    "        if self.label == \"multilabel\":\n",
    "            item[\"target\"]=tensor(self.data[[\"activatedby_HA\", \"activatedby_NP\", \"activatedby_HCRT\"]].iloc[index],dtype =torch.long)\n",
    "        else:\n",
    "            item[\"target\"] = tensor(self.data[self.label][index], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create writter \n",
    "writer = SummaryWriter(log_dir=\"runs/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tonekizer from tokenizers library \n",
    "if settings[\"param\"][\"tokenizer\"] == \"BPE\":\n",
    "    tokenizer = Tokenizer(BPE()).from_file(settings[\"tokenizer\"][\"BPE\"])\n",
    "elif settings[\"param\"][\"tokenizer\"] == \"WL\":\n",
    "    tokenizer = Tokenizer(WordLevel()).from_file(settings[\"tokenizer\"][\"WL\"])\n",
    "else:\n",
    "    raise ValueError(\"Unknown tokenizer. Tokenizer argument must be BPE or WL.\")\n",
    "tokenizer.enable_padding()\n",
    "    \n",
    "# Create training and test dataset\n",
    "dataset_params={\"label\":settings[\"database\"][\"label\"], \"tokenizer\":tokenizer}\n",
    "train_data = CDR3Dataset(settings,train=True, equal=False, **dataset_params)\n",
    "test_data =CDR3Dataset(settings, train=False, **dataset_params)\n",
    "\n",
    "# Crate dataloaders\n",
    "loader_params = {'batch_size': 20,\n",
    "            'shuffle': True,\n",
    "            'num_workers': 0\n",
    "            }\n",
    "train_dataloader = DataLoader(train_data, **loader_params)\n",
    "test_dataloader = DataLoader(test_data, **loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CAASEGAQKLVF_CASSFPLRGIYEQYF'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test tokenizers\n",
    "bpe_tokenizer = Tokenizer(BPE()).from_file(settings[\"tokenizer\"][\"BPE\"])\n",
    "wl_tokenizer = Tokenizer(WordLevel()).from_file(settings[\"tokenizer\"][\"WL\"])\n",
    "bpe_tokenizer.enable_padding()\n",
    "wl_tokenizer.enable_padding()\n",
    "\n",
    "# Get 10 random CDRs and predict \n",
    "sample_train = next(iter(train_dataloader))\n",
    "cdr = sample_train['CDR3ab'][0]\n",
    "cdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ids: [388, 6, 403, 5, 1554, 1018]\n",
      "Tokens: ['Ġcavi', 'a', 'kllf', '_', 'casslap', 'seklff']\n",
      "Vocab size:3817\n"
     ]
    }
   ],
   "source": [
    "# Get example\n",
    "cdr = sample_train['CDR3ab'][0]\n",
    "encoded = bpe_tokenizer.encode(cdr)\n",
    "decoded = bpe_tokenizer.decode(encoded.ids)\n",
    "print(\"Ids: \" + str(encoded.ids))\n",
    "print(\"Tokens: \" + str(encoded.tokens))\n",
    "print(\"Vocab size:\" + str(bpe_tokenizer.get_vocab_size()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ids: [9, 7, 7, 5, 17, 6, 7, 12, 19, 11, 16, 8, 15, 9, 7, 5, 5, 8, 22, 11, 18, 6, 21, 13, 17, 12, 13, 8]\n",
      "Tokens: ['c', 'a', 'a', 's', 'e', 'g', 'a', 'q', 'k', 'l', 'v', 'f', '_', 'c', 'a', 's', 's', 'f', 'p', 'l', 'r', 'g', 'i', 'y', 'e', 'q', 'y', 'f']\n"
     ]
    }
   ],
   "source": [
    "# Get example 2\n",
    "encoded = wl_tokenizer.encode(\" \".join(cdr))\n",
    "decoded = wl_tokenizer.decode(encoded.ids)\n",
    "print(\"Ids: \" + str(encoded.ids))\n",
    "print(\"Tokens: \" + str(encoded.tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDR3ab</th>\n",
       "      <th>activatedby_HA</th>\n",
       "      <th>activatedby_NP</th>\n",
       "      <th>activatedby_HCRT</th>\n",
       "      <th>PROB_activatedby_HA</th>\n",
       "      <th>PROB_activatedby_NP</th>\n",
       "      <th>PROB_activatedby_HCRT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAESRYNTDKLIF_CASRDYVGGGTEAFF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CIVIQTWAVEKLTF_CASSPTGVSYEQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAVGEGNNDMRF_CASSPGVGGNQPQHF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAVRDNDYKLSF_CASSQDALVTDTQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAVRLDSWGKLQF_CASSPLSSGGNTIYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CATGVYGQNFVF_CASSLGDRGQYEQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CAYRRRDDKIIF_CASSLAGAHTEAFF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CAVSVGGNKLVF_CASSSSGSRNQPQHF</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CATALYNTDKLIF_CASSQGATGGTNYGYTF</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CAMSSGGSNYKLTF_CASSPGWGNQPQHF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CAASGYGGSQGNLIF_CASSFSAGSYNEQFF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CAGPTGGSYIPTF_CASSFQGLSTDTQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CAVRNDYKLSF_CASSPRRQGYEQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAVSGWGNTPLVF_CASSVTGGGNEQFF</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CAASLYNFNKFYF_CASSDRGSYNSPLHF</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CALSADNFNKFYF_CASSPRAGANQPQHF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CAVSERGFQKLVF_CASSLVLGTQETQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CAVRPNDYKLSF_CASSSPGRGETEAFF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CAAPPNAGGTSYGKLTF_CASSPSGGRNEKLFF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CAVSEKNTGFQKLVF_CASRKGLGDTDTQYF</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               CDR3ab  activatedby_HA  activatedby_NP  \\\n",
       "0       CAESRYNTDKLIF_CASRDYVGGGTEAFF               0               0   \n",
       "1       CIVIQTWAVEKLTF_CASSPTGVSYEQYF               0               0   \n",
       "2        CAVGEGNNDMRF_CASSPGVGGNQPQHF               0               1   \n",
       "3        CAVRDNDYKLSF_CASSQDALVTDTQYF               0               0   \n",
       "4       CAVRLDSWGKLQF_CASSPLSSGGNTIYF               0               0   \n",
       "5        CATGVYGQNFVF_CASSLGDRGQYEQYF               0               1   \n",
       "6         CAYRRRDDKIIF_CASSLAGAHTEAFF               0               0   \n",
       "7        CAVSVGGNKLVF_CASSSSGSRNQPQHF               1               1   \n",
       "8     CATALYNTDKLIF_CASSQGATGGTNYGYTF               1               0   \n",
       "9       CAMSSGGSNYKLTF_CASSPGWGNQPQHF               0               0   \n",
       "10    CAASGYGGSQGNLIF_CASSFSAGSYNEQFF               0               0   \n",
       "11      CAGPTGGSYIPTF_CASSFQGLSTDTQYF               0               0   \n",
       "12         CAVRNDYKLSF_CASSPRRQGYEQYF               0               0   \n",
       "13       CAVSGWGNTPLVF_CASSVTGGGNEQFF               1               0   \n",
       "14      CAASLYNFNKFYF_CASSDRGSYNSPLHF               1               0   \n",
       "15      CALSADNFNKFYF_CASSPRAGANQPQHF               0               0   \n",
       "16      CAVSERGFQKLVF_CASSLVLGTQETQYF               0               1   \n",
       "17       CAVRPNDYKLSF_CASSSPGRGETEAFF               0               0   \n",
       "18  CAAPPNAGGTSYGKLTF_CASSPSGGRNEKLFF               0               0   \n",
       "19    CAVSEKNTGFQKLVF_CASRKGLGDTDTQYF               1               0   \n",
       "\n",
       "    activatedby_HCRT  PROB_activatedby_HA  PROB_activatedby_NP  \\\n",
       "0                  0                0.150                0.000   \n",
       "1                  0                0.002                0.000   \n",
       "2                  0                0.000                0.999   \n",
       "3                  0                0.001                0.000   \n",
       "4                  0                0.000                0.000   \n",
       "5                  0                0.000                0.999   \n",
       "6                  0                0.000                0.036   \n",
       "7                  0                0.987                0.962   \n",
       "8                  0                0.986                0.001   \n",
       "9                  0                0.003                0.000   \n",
       "10                 0                0.261                0.000   \n",
       "11                 0                0.001                0.000   \n",
       "12                 1                0.000                0.002   \n",
       "13                 0                0.991                0.004   \n",
       "14                 1                0.967                0.000   \n",
       "15                 1                0.000                0.002   \n",
       "16                 0                0.000                0.999   \n",
       "17                 0                0.002                0.000   \n",
       "18                 0                0.002                0.000   \n",
       "19                 0                0.990                0.002   \n",
       "\n",
       "    PROB_activatedby_HCRT  \n",
       "0                   0.000  \n",
       "1                   0.000  \n",
       "2                   0.000  \n",
       "3                   0.000  \n",
       "4                   0.000  \n",
       "5                   0.000  \n",
       "6                   0.000  \n",
       "7                   0.000  \n",
       "8                   0.001  \n",
       "9                   0.000  \n",
       "10                  0.000  \n",
       "11                  0.000  \n",
       "12                  0.999  \n",
       "13                  0.000  \n",
       "14                  0.990  \n",
       "15                  0.999  \n",
       "16                  0.000  \n",
       "17                  0.000  \n",
       "18                  0.000  \n",
       "19                  0.000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get 10 random CDRs and predict \n",
    "sample_train = next(iter(train_dataloader))\n",
    "\n",
    "# Predict \n",
    "torch.cuda.empty_cache() \n",
    "model.eval()\n",
    "outs_df = []\n",
    "ids = sample_train[\"ids\"].to(device)\n",
    "attention_mask = sample_train[\"attention_mask\"].to(device)\n",
    "targets = sample_train[\"target\"].to(device)\n",
    "outs = model(ids, attention_mask)\n",
    "\n",
    "# Bring to CPU \n",
    "targets = targets.to('cpu') .detach().numpy()\n",
    "outs = outs.to('cpu')\n",
    "outs = outs.detach().numpy()\n",
    "outs = np.around(outs, decimals=3) \n",
    "\n",
    "cols_prob = [\"PROB_activatedby_HA\", \"PROB_activatedby_NP\", \"PROB_activatedby_HCRT\"]\n",
    "cols = [\"activatedby_HA\", \"activatedby_NP\", \"activatedby_HCRT\"]\n",
    "\n",
    "# Crate dataframes \n",
    "outs_df = pd.DataFrame.from_records(outs)\n",
    "outs_df.columns = cols_prob\n",
    "\n",
    "# Crate dataframe of targets\n",
    "targets_df = pd.DataFrame.from_records(targets)\n",
    "targets_df.columns = cols\n",
    "targets_df.insert(0, 'CDR3ab', sample_train['CDR3ab'])\n",
    "\n",
    "# Concat \n",
    "comp_df = pd.concat([targets_df, outs_df], axis=1)\n",
    "comp_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDR3ab</th>\n",
       "      <th>activatedby_HA</th>\n",
       "      <th>activatedby_NP</th>\n",
       "      <th>activatedby_HCRT</th>\n",
       "      <th>PROB_activatedby_HA</th>\n",
       "      <th>PROB_activatedby_NP</th>\n",
       "      <th>PROB_activatedby_HCRT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAVNYLGGKLIF_CASSPGTGGNSPLHF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALITGSARQLTF_CASSLTSGETNEQFF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CALSYSNYQLIW_CASSEGTGDYGYTF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAVNARLMF_CASSTQGAGEAFF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAVTSNFGNEKLTF_CASSFRQGSSYEQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CAPRRGAQKLVF_CASSELVADTQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CAPRGSGNTPLVF_CASSTVQGASEKLFF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CALGDTGRRALTF_CASSTGTGGYNEQFF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CIVRRVYGGSQGNLIF_CASSLGGQQGGDTQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CAVSTSSNYKLTF_CASSSQTAGANVLTF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CAVRRGGADGLTF_CATSRDGSYEQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CILRAYGNKLVF_CASSRSGQSIQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CAVSPGFKTIF_CASSEGQGTDTQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAARTFGNEKLTF_CAISATTDTQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CAMVIQGAQKLVF_CASSQDRHWEAFF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CAVRDSGYSTLTF_CASSPEGAWEQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CAVSGYNTDKLIF_CASSHSTDTQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CAVRSGGSNYKLTF_CASSSGTGVYEQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CAMRDGGFKTIF_CASSSLTGGDYGYTF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CAVYNNAGNMLTF_CASSDSVSGDEETQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               CDR3ab  activatedby_HA  activatedby_NP  \\\n",
       "0        CAVNYLGGKLIF_CASSPGTGGNSPLHF               0               1   \n",
       "1       CALITGSARQLTF_CASSLTSGETNEQFF               0               0   \n",
       "2         CALSYSNYQLIW_CASSEGTGDYGYTF               0               0   \n",
       "3             CAVNARLMF_CASSTQGAGEAFF               0               0   \n",
       "4      CAVTSNFGNEKLTF_CASSFRQGSSYEQYF               0               0   \n",
       "5          CAPRRGAQKLVF_CASSELVADTQYF               0               0   \n",
       "6       CAPRGSGNTPLVF_CASSTVQGASEKLFF               0               0   \n",
       "7       CALGDTGRRALTF_CASSTGTGGYNEQFF               0               0   \n",
       "8   CIVRRVYGGSQGNLIF_CASSLGGQQGGDTQYF               0               0   \n",
       "9       CAVSTSSNYKLTF_CASSSQTAGANVLTF               0               0   \n",
       "10        CAVRRGGADGLTF_CATSRDGSYEQYF               0               0   \n",
       "11         CILRAYGNKLVF_CASSRSGQSIQYF               0               0   \n",
       "12         CAVSPGFKTIF_CASSEGQGTDTQYF               0               0   \n",
       "13         CAARTFGNEKLTF_CAISATTDTQYF               0               1   \n",
       "14        CAMVIQGAQKLVF_CASSQDRHWEAFF               0               1   \n",
       "15        CAVRDSGYSTLTF_CASSPEGAWEQYF               0               1   \n",
       "16         CAVSGYNTDKLIF_CASSHSTDTQYF               0               1   \n",
       "17      CAVRSGGSNYKLTF_CASSSGTGVYEQYF               0               0   \n",
       "18       CAMRDGGFKTIF_CASSSLTGGDYGYTF               0               0   \n",
       "19     CAVYNNAGNMLTF_CASSDSVSGDEETQYF               0               0   \n",
       "\n",
       "    activatedby_HCRT  PROB_activatedby_HA  PROB_activatedby_NP  \\\n",
       "0                  0                0.840                0.992   \n",
       "1                  0                0.000                0.127   \n",
       "2                  0                0.000                0.029   \n",
       "3                  0                0.002                0.000   \n",
       "4                  0                0.001                0.000   \n",
       "5                  0                0.001                0.000   \n",
       "6                  0                0.001                0.000   \n",
       "7                  0                0.002                0.000   \n",
       "8                  0                0.009                0.000   \n",
       "9                  0                0.000                0.000   \n",
       "10                 0                0.000                0.000   \n",
       "11                 0                0.000                0.001   \n",
       "12                 0                0.001                0.000   \n",
       "13                 0                0.000                0.998   \n",
       "14                 0                0.000                0.999   \n",
       "15                 0                0.000                0.181   \n",
       "16                 0                0.000                0.999   \n",
       "17                 0                0.012                0.000   \n",
       "18                 0                0.001                0.000   \n",
       "19                 0                0.012                0.000   \n",
       "\n",
       "    PROB_activatedby_HCRT  \n",
       "0                   0.000  \n",
       "1                   0.000  \n",
       "2                   0.000  \n",
       "3                   0.000  \n",
       "4                   0.000  \n",
       "5                   0.000  \n",
       "6                   0.000  \n",
       "7                   0.000  \n",
       "8                   0.000  \n",
       "9                   0.000  \n",
       "10                  0.000  \n",
       "11                  0.891  \n",
       "12                  0.000  \n",
       "13                  0.000  \n",
       "14                  0.000  \n",
       "15                  0.000  \n",
       "16                  0.000  \n",
       "17                  0.000  \n",
       "18                  0.000  \n",
       "19                  0.000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get 10 random CDRs and predict \n",
    "sample_test = next(iter(test_dataloader))\n",
    "\n",
    "# Predict \n",
    "model.eval()\n",
    "outs_df = []\n",
    "ids = sample_test[\"ids\"].to(device)\n",
    "attention_mask = sample_test[\"attention_mask\"].to(device)\n",
    "targets = sample_test[\"target\"].to(device)\n",
    "outs = model(ids, attention_mask)\n",
    "\n",
    "# Bring to CPU \n",
    "targets = targets.to('cpu') .detach().numpy()\n",
    "outs = outs.to('cpu')\n",
    "outs = outs.detach().numpy()\n",
    "outs = np.around(outs, decimals=3) \n",
    "\n",
    "cols_prob = [\"PROB_activatedby_HA\", \"PROB_activatedby_NP\", \"PROB_activatedby_HCRT\"]\n",
    "cols = [\"activatedby_HA\", \"activatedby_NP\", \"activatedby_HCRT\"]\n",
    "\n",
    "# Crate dataframes \n",
    "outs_df = pd.DataFrame.from_records(outs)\n",
    "outs_df.columns = cols_prob\n",
    "\n",
    "# Crate dataframe of targets\n",
    "targets_df = pd.DataFrame.from_records(targets)\n",
    "targets_df.columns = cols\n",
    "targets_df.insert(0, 'CDR3ab', sample_test['CDR3ab'])\n",
    "\n",
    "# Concat \n",
    "comp_df = pd.concat([targets_df, outs_df], axis=1)\n",
    "comp_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative      2783\n",
       "NP136          766\n",
       "HA69           535\n",
       "HCRT           269\n",
       "HCRT|NP136      33\n",
       "HA69|NP136      28\n",
       "HA69|HCRT        6\n",
       "Name: activated_by, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data \n",
    "train_data.data.activated_by.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4420"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative      1174\n",
       "NP136          365\n",
       "HA69           192\n",
       "HCRT           143\n",
       "HA69|NP136      14\n",
       "HCRT|NP136       6\n",
       "Name: activated_by, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.activated_by.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1894"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1682\n",
       "0     212\n",
       "Name: activatedby_NP, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.activatedby_NP.value_counts()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
