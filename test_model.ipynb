{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import torch \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "import tokenizers\n",
    "\n",
    "from torch import tensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import  RobertaConfig\n",
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers import pre_tokenizers, normalizers, Tokenizer\n",
    "from tokenizers.normalizers import Lowercase, NFD\n",
    "from tokenizers.pre_tokenizers import ByteLevel, Whitespace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (l1): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(4050, 1032, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 1032, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(2, 1032)\n",
       "      (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (key): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (value): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "              (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1032, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1032, bias=True)\n",
       "            (LayerNorm): LayerNorm((1032,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=1032, out_features=1032, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1032, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load settings\n",
    "with open('settings.json', 'r') as inFile:\n",
    "    settings = json.load(inFile)\n",
    "    \n",
    "# Set device \n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load model\n",
    "model = torch.load('best_model')\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDR3Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, settings:dict, train:bool = True, label:str = None, tokenizer:tokenizers.Tokenizer=None, equal:bool=False) -> None:\n",
    "        cols = [\"activatedby_HA\", \"activatedby_NP\", \"activatedby_HCRT\", \"activated_any\", \"multilabel\", \"negative\"]\n",
    "        if label not in cols:\n",
    "            raise ValueError(\"Invalid label type. Expected one of %s\" % cols)\n",
    "        else: \n",
    "            self.label = label\n",
    "        if equal and label == \"num_label\":\n",
    "            raise ValueError(\"Equal size sets only allowed for binary classifications. num_label is multiclass.\")\n",
    "        \n",
    "        if train == True:\n",
    "            path_to_data = settings[\"file\"][\"train_data\"] \n",
    "        else:\n",
    "            path_to_data = settings[\"file\"][\"test_data\"]   \n",
    "              \n",
    "        self.path_to_data = path_to_data\n",
    "        self.data = pd.read_csv(self.path_to_data)\n",
    "        if equal == True:\n",
    "            min_sample=np.min(self.data[self.label].value_counts()) \n",
    "            data_pos = self.data[self.data[self.label]==1].sample(min_sample)\n",
    "            data_neg = self.data[self.data[self.label]==0].sample(min_sample)\n",
    "            self.data = pd.concat([data_pos, data_neg], ignore_index=True)\n",
    "        \n",
    "        if label == \"multilabel\":\n",
    "            self.labels = [0,1]\n",
    "            self.n_labels = 4\n",
    "        else:\n",
    "            self.labels = np.unique(self.data[[self.label]])\n",
    "            self.n_labels = len(self.labels)\n",
    "            \n",
    "        self.max_len = self.data.CDR3ab.str.len().max()\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __getitem__(self, index:int):\n",
    "        if isinstance(self.tokenizer, tokenizers.Tokenizer):\n",
    "            self.tokenizer.enable_padding(length=self.max_len)\n",
    "            CDR3ab = \" \".join(list(self.data.CDR3ab[index]))\n",
    "            encodings = self.tokenizer.encode(CDR3ab)\n",
    "            item = {\n",
    "                \"ids\":tensor(encodings.ids, dtype=torch.long),\n",
    "                \"attention_mask\": tensor(encodings.attention_mask, dtype=torch.long), \n",
    "                \"CDR3ab\": self.data.CDR3ab[index]\n",
    "                }\n",
    "        else:\n",
    "            self.tokenizer.enable_padding(length=self.max_len)\n",
    "            encodings = self.tokenizer.encode(self.data.CDR3ab[index]) \n",
    "            item = {\n",
    "                \"ids\":tensor(encodings.ids, dtype=torch.long),\n",
    "                \"attention_mask\": tensor(encodings.attention_mask, dtype=torch.long),\n",
    "                \"CDR3ab\": self.data.CDR3ab[index]\n",
    "                }\n",
    "        if self.label == \"multilabel\":\n",
    "            item[\"target\"]=tensor(self.data[[\"activatedby_HA\", \"activatedby_NP\", \"activatedby_HCRT\", \"negative\"]].iloc[index],dtype =torch.long)\n",
    "        else:\n",
    "            item[\"target\"] = tensor(self.data[self.label][index], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tonekizer from tokenizers library \n",
    "if settings[\"param\"][\"tokenizer\"] == \"BPE\":\n",
    "    normalizer = normalizers.Sequence([Lowercase(), NFD()])\n",
    "    pre_tokenizer = pre_tokenizers.Sequence([ByteLevel()])\n",
    "    tokenizer = ByteLevelBPETokenizer(settings[\"tokenizer\"][\"BPE_vocab\"], settings[\"tokenizer\"][\"BPE_merge\"])\n",
    "    tokenizer.normalizer = normalizer\n",
    "    tokenizer.pre_tokenizer = pre_tokenizer\n",
    "elif settings[\"param\"][\"tokenizer\"] == \"WL\":\n",
    "    normalizer = normalizers.Sequence([Lowercase(), NFD()])\n",
    "    pre_tokenizer = pre_tokenizers.Sequence([Whitespace()])\n",
    "    tokenizer = Tokenizer(WordLevel()).from_file(settings[\"tokenizer\"][\"WL\"])\n",
    "    tokenizer.pre_tokenizer = pre_tokenizer\n",
    "    tokenizer.normalizer = normalizer\n",
    "    tokenizer.enable_padding()\n",
    "else:\n",
    "    raise ValueError(\"Unknown tokenizer. Tokenizer argument must be BPE or WL.\")\n",
    "    \n",
    "# Create training and test dataset\n",
    "dataset_params={\"label\":settings[\"database\"][\"label\"], \"tokenizer\":tokenizer}\n",
    "train_data = CDR3Dataset(settings,train=True, equal=False, **dataset_params)\n",
    "test_data =CDR3Dataset(settings, train=False, **dataset_params)\n",
    "\n",
    "# Crate dataloaders\n",
    "loader_params = {'batch_size': 20,\n",
    "            'shuffle': True,\n",
    "            'num_workers': 0\n",
    "            }\n",
    "train_dataloader = DataLoader(train_data, **loader_params)\n",
    "test_dataloader = DataLoader(test_data, **loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDR3ab</th>\n",
       "      <th>activatedby_HA</th>\n",
       "      <th>activatedby_NP</th>\n",
       "      <th>activatedby_HCRT</th>\n",
       "      <th>negative</th>\n",
       "      <th>PROB_activatedby_HA</th>\n",
       "      <th>PROB_activatedby_NP</th>\n",
       "      <th>PROB_activatedby_HCRT</th>\n",
       "      <th>PROB_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAVLGGGSRLTF_CASSLSLGPQHF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAVESNSGYALNF_CASSYGGLASDTQYF</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CVVRGGSGGSYIPTF_CASSLWGQDYGYTF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAVETDSWGKLQF_CASSLAPGRDRFFYEQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAETSLYTGRRALTF_CASSQDDLREGELFF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CAVGSGTYKYIF_CSARLAGHTDTQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CAVETDSWGKLQF_CASSQGQGTDTQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CAVETDSWGKFQF_CAWNGQGNEKLFF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CAVEPFTDKLIF_CASSHLLNTEAFF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CAVRILTGGGNKLTF_CASSHSTDTQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CIVRVGTNQAGTALIF_CSARDQLAGENEQFF</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CAGPRSGYSTLTF_CASSPRTDSNQPQHF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CAVGDSGTYKYIF_CASSWGLAGGGGELFF</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAVSRGAAGNKLTF_CASSSLAGGQETQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CAMRARDQGAQKLVF_CASSFEANTGELFF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CAEMYTGGFKTIF_CASSLPGAGNTIYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CAVSGSGGSYIPTF_CASSVGGLAASNEQFF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CAVGARYGGSQGNLIF_CASSLDPGGSAYEQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CAASAGGNTPLVF_CASSRLENEQFF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CAVQEAGSNYKLTF_CASSPVLAGTYEQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               CDR3ab  activatedby_HA  activatedby_NP  \\\n",
       "0           CAVLGGGSRLTF_CASSLSLGPQHF               0               0   \n",
       "1       CAVESNSGYALNF_CASSYGGLASDTQYF               1               0   \n",
       "2      CVVRGGSGGSYIPTF_CASSLWGQDYGYTF               0               1   \n",
       "3    CAVETDSWGKLQF_CASSLAPGRDRFFYEQYF               0               0   \n",
       "4     CAETSLYTGRRALTF_CASSQDDLREGELFF               0               0   \n",
       "5         CAVGSGTYKYIF_CSARLAGHTDTQYF               0               0   \n",
       "6        CAVETDSWGKLQF_CASSQGQGTDTQYF               0               0   \n",
       "7         CAVETDSWGKFQF_CAWNGQGNEKLFF               0               0   \n",
       "8          CAVEPFTDKLIF_CASSHLLNTEAFF               0               0   \n",
       "9        CAVRILTGGGNKLTF_CASSHSTDTQYF               0               0   \n",
       "10   CIVRVGTNQAGTALIF_CSARDQLAGENEQFF               1               0   \n",
       "11      CAGPRSGYSTLTF_CASSPRTDSNQPQHF               0               1   \n",
       "12     CAVGDSGTYKYIF_CASSWGLAGGGGELFF               1               0   \n",
       "13     CAVSRGAAGNKLTF_CASSSLAGGQETQYF               0               0   \n",
       "14     CAMRARDQGAQKLVF_CASSFEANTGELFF               0               0   \n",
       "15       CAEMYTGGFKTIF_CASSLPGAGNTIYF               0               0   \n",
       "16    CAVSGSGGSYIPTF_CASSVGGLAASNEQFF               0               0   \n",
       "17  CAVGARYGGSQGNLIF_CASSLDPGGSAYEQYF               0               0   \n",
       "18         CAASAGGNTPLVF_CASSRLENEQFF               0               0   \n",
       "19     CAVQEAGSNYKLTF_CASSPVLAGTYEQYF               0               1   \n",
       "\n",
       "    activatedby_HCRT  negative  PROB_activatedby_HA  PROB_activatedby_NP  \\\n",
       "0                  0         1                0.001                0.000   \n",
       "1                  0         0                0.917                0.002   \n",
       "2                  0         0                0.013                0.995   \n",
       "3                  0         1                0.001                0.001   \n",
       "4                  0         1                0.001                0.000   \n",
       "5                  1         0                0.016                0.007   \n",
       "6                  0         1                0.001                0.001   \n",
       "7                  1         0                0.018                0.013   \n",
       "8                  1         0                0.016                0.008   \n",
       "9                  0         1                0.001                0.000   \n",
       "10                 0         0                0.948                0.002   \n",
       "11                 0         0                0.015                0.997   \n",
       "12                 0         0                0.968                0.002   \n",
       "13                 0         1                0.001                0.001   \n",
       "14                 0         1                0.001                0.000   \n",
       "15                 0         1                0.003                0.001   \n",
       "16                 0         1                0.001                0.000   \n",
       "17                 0         1                0.001                0.000   \n",
       "18                 0         1                0.001                0.001   \n",
       "19                 0         0                0.017                0.993   \n",
       "\n",
       "    PROB_activatedby_HCRT  PROB_negative  \n",
       "0                   0.001          0.998  \n",
       "1                   0.015          0.040  \n",
       "2                   0.003          0.002  \n",
       "3                   0.001          0.998  \n",
       "4                   0.001          0.998  \n",
       "5                   0.889          0.077  \n",
       "6                   0.001          0.997  \n",
       "7                   0.845          0.106  \n",
       "8                   0.811          0.138  \n",
       "9                   0.001          0.998  \n",
       "10                  0.003          0.037  \n",
       "11                  0.002          0.001  \n",
       "12                  0.002          0.017  \n",
       "13                  0.001          0.998  \n",
       "14                  0.001          0.998  \n",
       "15                  0.004          0.992  \n",
       "16                  0.001          0.998  \n",
       "17                  0.001          0.998  \n",
       "18                  0.001          0.998  \n",
       "19                  0.005          0.003  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get 10 random CDRs and predict \n",
    "sample_train = next(iter(train_dataloader))\n",
    "\n",
    "# Predict \n",
    "torch.cuda.empty_cache() \n",
    "model.eval()\n",
    "outs_df = []\n",
    "ids = sample_train[\"ids\"].to(device)\n",
    "attention_mask = sample_train[\"attention_mask\"].to(device)\n",
    "targets = sample_train[\"target\"].to(device)\n",
    "outs = model(ids, attention_mask)\n",
    "\n",
    "# Bring to CPU \n",
    "targets = targets.to('cpu') .detach().numpy()\n",
    "outs = outs.to('cpu')\n",
    "outs = outs.detach().numpy()\n",
    "outs = np.around(outs, decimals=3) \n",
    "\n",
    "cols_prob = [\"PROB_activatedby_HA\", \"PROB_activatedby_NP\", \"PROB_activatedby_HCRT\", \"PROB_negative\"]\n",
    "cols = [\"activatedby_HA\", \"activatedby_NP\", \"activatedby_HCRT\", \"negative\"]\n",
    "\n",
    "# Crate dataframes \n",
    "outs_df = pd.DataFrame.from_records(outs)\n",
    "outs_df.columns = cols_prob\n",
    "\n",
    "# Crate dataframe of targets\n",
    "targets_df = pd.DataFrame.from_records(targets)\n",
    "targets_df.columns = cols\n",
    "targets_df.insert(0, 'CDR3ab', sample_train['CDR3ab'])\n",
    "\n",
    "# Concat \n",
    "comp_df = pd.concat([targets_df, outs_df], axis=1)\n",
    "comp_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDR3ab</th>\n",
       "      <th>activatedby_HA</th>\n",
       "      <th>activatedby_NP</th>\n",
       "      <th>activatedby_HCRT</th>\n",
       "      <th>negative</th>\n",
       "      <th>PROB_activatedby_HA</th>\n",
       "      <th>PROB_activatedby_NP</th>\n",
       "      <th>PROB_activatedby_HCRT</th>\n",
       "      <th>PROB_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAASAGSWGKLQF_CASSLRGQGGKLFF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAVEPGNTGKLIF_CASSLAGPNIQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CALWRGSQGNLIF_CASSVRGGFYEQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAPRGYGQNFVF_CAWSPTQGTKNIQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAVSRYGGATNKLIF_CASSLLGLASEQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CATDGESGAGSYQLTF_CASSPHRGRKYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CAVTGNQGGKLIF_CASSSPGQSYEQYF</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CAVEDSGYSTLTF_CASSPTMEQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CAVKAGGFKTIF_CASSTGTDSNQPQHF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CAASKGAQKLVF_CASSPDYPPGGEQFF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CAVSDSGGYQKVTF_CASSIVGRGSVEQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CAVMNTGNQFYF_CASRSRPGGNEQFF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CAVRPTGTASKLTF_CASSVGLDRYNEQFF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAVTYSGYSTLTF_CASSQDTGNQPQHF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CAYRSASGTYKYIF_CASSYVFTGTGELFF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CAVTWLGGKLTF_CSARLIPTGGTEAFF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CAATVQGGSEKLVF_CASSPADSIPEQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CAEVNGGATNKLIF_CASTDRGRNTIYF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CIVRVAGGSNYKLTF_CASSEALAGTGELFF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CAVRGTGANNLFF_CASSLQGESQETQYF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             CDR3ab  activatedby_HA  activatedby_NP  \\\n",
       "0      CAASAGSWGKLQF_CASSLRGQGGKLFF               0               0   \n",
       "1       CAVEPGNTGKLIF_CASSLAGPNIQYF               0               0   \n",
       "2      CALWRGSQGNLIF_CASSVRGGFYEQYF               0               0   \n",
       "3      CAPRGYGQNFVF_CAWSPTQGTKNIQYF               0               0   \n",
       "4    CAVSRYGGATNKLIF_CASSLLGLASEQYF               0               0   \n",
       "5     CATDGESGAGSYQLTF_CASSPHRGRKYF               0               0   \n",
       "6      CAVTGNQGGKLIF_CASSSPGQSYEQYF               1               0   \n",
       "7         CAVEDSGYSTLTF_CASSPTMEQYF               0               1   \n",
       "8      CAVKAGGFKTIF_CASSTGTDSNQPQHF               0               1   \n",
       "9      CAASKGAQKLVF_CASSPDYPPGGEQFF               0               1   \n",
       "10   CAVSDSGGYQKVTF_CASSIVGRGSVEQYF               0               0   \n",
       "11      CAVMNTGNQFYF_CASRSRPGGNEQFF               0               1   \n",
       "12   CAVRPTGTASKLTF_CASSVGLDRYNEQFF               0               0   \n",
       "13     CAVTYSGYSTLTF_CASSQDTGNQPQHF               0               1   \n",
       "14   CAYRSASGTYKYIF_CASSYVFTGTGELFF               0               0   \n",
       "15     CAVTWLGGKLTF_CSARLIPTGGTEAFF               0               1   \n",
       "16    CAATVQGGSEKLVF_CASSPADSIPEQYF               0               0   \n",
       "17     CAEVNGGATNKLIF_CASTDRGRNTIYF               0               0   \n",
       "18  CIVRVAGGSNYKLTF_CASSEALAGTGELFF               0               1   \n",
       "19    CAVRGTGANNLFF_CASSLQGESQETQYF               0               1   \n",
       "\n",
       "    activatedby_HCRT  negative  PROB_activatedby_HA  PROB_activatedby_NP  \\\n",
       "0                  0         1                0.854                0.001   \n",
       "1                  0         1                0.001                0.001   \n",
       "2                  1         0                0.517                0.003   \n",
       "3                  0         1                0.077                0.004   \n",
       "4                  1         0                0.001                0.001   \n",
       "5                  0         1                0.001                0.000   \n",
       "6                  0         0                0.002                0.000   \n",
       "7                  0         0                0.081                0.973   \n",
       "8                  0         0                0.086                0.131   \n",
       "9                  0         0                0.027                0.994   \n",
       "10                 1         0                0.016                0.009   \n",
       "11                 0         0                0.001                0.002   \n",
       "12                 0         1                0.001                0.001   \n",
       "13                 0         0                0.024                0.996   \n",
       "14                 0         1                0.001                0.001   \n",
       "15                 0         0                0.001                0.000   \n",
       "16                 0         1                0.047                0.991   \n",
       "17                 0         1                0.004                0.003   \n",
       "18                 0         0                0.001                0.000   \n",
       "19                 0         0                0.031                0.983   \n",
       "\n",
       "    PROB_activatedby_HCRT  PROB_negative  \n",
       "0                   0.002          0.161  \n",
       "1                   0.001          0.997  \n",
       "2                   0.054          0.543  \n",
       "3                   0.005          0.951  \n",
       "4                   0.001          0.998  \n",
       "5                   0.001          0.999  \n",
       "6                   0.001          0.997  \n",
       "7                   0.001          0.021  \n",
       "8                   0.001          0.730  \n",
       "9                   0.004          0.002  \n",
       "10                  0.802          0.144  \n",
       "11                  0.001          0.996  \n",
       "12                  0.001          0.998  \n",
       "13                  0.002          0.001  \n",
       "14                  0.001          0.998  \n",
       "15                  0.001          0.998  \n",
       "16                  0.004          0.003  \n",
       "17                  0.010          0.984  \n",
       "18                  0.001          0.998  \n",
       "19                  0.006          0.010  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get 10 random CDRs and predict \n",
    "sample_test = next(iter(test_dataloader))\n",
    "\n",
    "# Predict \n",
    "model.eval()\n",
    "outs_df = []\n",
    "ids = sample_test[\"ids\"].to(device)\n",
    "attention_mask = sample_test[\"attention_mask\"].to(device)\n",
    "targets = sample_test[\"target\"].to(device)\n",
    "outs = model(ids, attention_mask)\n",
    "\n",
    "# Bring to CPU \n",
    "targets = targets.to('cpu') .detach().numpy()\n",
    "outs = outs.to('cpu')\n",
    "outs = outs.detach().numpy()\n",
    "outs = np.around(outs, decimals=3) \n",
    "\n",
    "cols_prob = [\"PROB_activatedby_HA\", \"PROB_activatedby_NP\", \"PROB_activatedby_HCRT\", \"PROB_negative\"]\n",
    "cols = [\"activatedby_HA\", \"activatedby_NP\", \"activatedby_HCRT\", \"negative\"]\n",
    "\n",
    "# Crate dataframes \n",
    "outs_df = pd.DataFrame.from_records(outs)\n",
    "outs_df.columns = cols_prob\n",
    "\n",
    "# Crate dataframe of targets\n",
    "targets_df = pd.DataFrame.from_records(targets)\n",
    "targets_df.columns = cols\n",
    "targets_df.insert(0, 'CDR3ab', sample_test['CDR3ab'])\n",
    "\n",
    "# Concat \n",
    "comp_df = pd.concat([targets_df, outs_df], axis=1)\n",
    "comp_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative      2783\n",
       "NP136          766\n",
       "HA69           535\n",
       "HCRT           269\n",
       "HCRT|NP136      33\n",
       "HA69|NP136      28\n",
       "HA69|HCRT        6\n",
       "Name: activated_by, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data \n",
    "train_data.data.activated_by.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative      1174\n",
       "NP136          365\n",
       "HA69           192\n",
       "HCRT           143\n",
       "HA69|NP136      14\n",
       "HCRT|NP136       6\n",
       "Name: activated_by, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.activated_by.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1682\n",
       "0     212\n",
       "Name: activatedby_NP, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.activatedby_NP.value_counts()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
